{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import finished\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "''' Imports '''\n",
    "\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os, csv\n",
    "import random\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image \n",
    "from IPython.display import display \n",
    "from PIL import Image\n",
    "from PIL import ImageFile \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.engine.topology import get_source_inputs\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "print(\"Import finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "''' Class '''\n",
    "\n",
    "class Traffic_Sign:\n",
    "    \"\"\" A Single Traffic sign model \"\"\"\n",
    "    \n",
    "    def __init__(self, filePath, fileName, width, height, x1, y1, x2, y2, classTxt, classID):\n",
    "        self.filePath = filePath\n",
    "        self.fileName = fileName\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "        self.classTxt = classTxt\n",
    "        self.classID = classID  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "''' Print helper function '''\n",
    "\n",
    "# pretty print Traffic Sign object\n",
    "def ts_pretty_print(ts):\n",
    "    print(\"File: {} has name {}, with classID: {}\".format(ts.fileName, ts.classTxt, ts.classID))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTSName_txt_path = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/Dataset/reducedSetTS.txt\"\\nlabel_map_output_path = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/obj_detection/data/TS_label_map.pbtxt\"\\n\\n# All standard pictures in this folder are with its class name and .png format e.g. A1A.png\\nstandard_folder = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/Standards/\"\\nstandard_img_extension = \".png\"\\n\\n# dataset path\\ndataset_directory = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/Dataset\"\\ntraining_dataset_directory = os.path.join(dataset_directory, \"Training\")\\ntesting_dataset_directory = os.path.join(dataset_directory, \"Testing\")\\n\\n# Store all images in png under training/testing folder\\npng_training_dataset_dir = os.path.join(dataset_directory, \\'png_training\\')\\npng_testing_dataset_dir = os.path.join(dataset_directory, \\'png_testing\\')\\n\\n# tfRecords output path\\ntfRecordsDir = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/obj_detection/tfRecords\"\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Mac'''\n",
    "\n",
    "TSName_txt_path = \"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset/reducedSetTS.txt\"\n",
    "label_map_output_path = \"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/obj_detection/data/TS_label_map.pbtxt\"\n",
    "\n",
    "# All standard pictures in this folder are with its class name and .png format e.g. A1A.png\n",
    "standard_folder = \"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Standards\"\n",
    "standard_img_extension = \".png\"\n",
    "\n",
    "# dataset path\n",
    "dataset_directory = \"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset\"\n",
    "training_dataset_directory = os.path.join(dataset_directory, \"Training\")\n",
    "testing_dataset_directory = os.path.join(dataset_directory, \"Testing\")\n",
    "\n",
    "# Store all images in png under training/testing folder\n",
    "png_training_dataset_dir = os.path.join(dataset_directory, 'png_training')\n",
    "png_testing_dataset_dir = os.path.join(dataset_directory, 'png_testing')\n",
    "\n",
    "# tfRecords output path\n",
    "tfRecordsDir = \"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/obj_detection/tfRecords\"\n",
    "\n",
    "'''Windows'''\n",
    "'''\n",
    "TSName_txt_path = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/Dataset/reducedSetTS.txt\"\n",
    "label_map_output_path = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/obj_detection/data/TS_label_map.pbtxt\"\n",
    "\n",
    "# All standard pictures in this folder are with its class name and .png format e.g. A1A.png\n",
    "standard_folder = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/Standards/\"\n",
    "standard_img_extension = \".png\"\n",
    "\n",
    "# dataset path\n",
    "dataset_directory = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/Dataset\"\n",
    "training_dataset_directory = os.path.join(dataset_directory, \"Training\")\n",
    "testing_dataset_directory = os.path.join(dataset_directory, \"Testing\")\n",
    "\n",
    "# Store all images in png under training/testing folder\n",
    "png_training_dataset_dir = os.path.join(dataset_directory, 'png_training')\n",
    "png_testing_dataset_dir = os.path.join(dataset_directory, 'png_testing')\n",
    "\n",
    "# tfRecords output path\n",
    "tfRecordsDir = \"C:/Users/ksu/Desktop/ML/TSR_capstone/MLND_Traffic_Sign_Recognition/obj_detection/tfRecords\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TS_label_map generator '''\n",
    "\n",
    "def label_generator(TSName_62_collection):\n",
    "    label_map_content = \"\"\n",
    "    num_of_classes = 62\n",
    "    for i in range(num_of_classes):\n",
    "        label_map_content += \"item{\\n\"\n",
    "        label_map_content += \"  name: \\\"{}\\\"\\n\".format(TSName_62_collection[i])\n",
    "        label_map_content += \"  id: {}\\n\".format(str(i+1))\n",
    "        label_map_content += \"}\\n\\n\"\n",
    "        \n",
    "    with open(label_map_output_path, \"w\") as fout:\n",
    "        fout.write(label_map_content) \n",
    "\n",
    "        \n",
    "# create classID and className pairs for 62 Traffic Signs\n",
    "with open(TSName_txt_path) as f:\n",
    "    TSName_62 = f.readlines()\n",
    "# remove whitespace characters\n",
    "TSName_62 = [x.strip() for x in TSName_62[0:]]\n",
    "\n",
    "\n",
    "# Generate label map for obj_detection\n",
    "label_generator(TSName_62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ppm to png converter generator '''\n",
    "\n",
    "# png_dataset_dir: destination of png files of either training datasets and testing datasets\n",
    "# img_path: the path to one single ppm image file. \n",
    "\n",
    "def convert_ppm_to_png(png_dataset_dir, ppm_img_path, ppm_img_name):\n",
    "    # if this path doesn't exist, create \n",
    "    if not os.path.exists(png_dataset_dir):\n",
    "        os.makedirs(png_dataset_dir)\n",
    "\n",
    "    if ppm_img_name[-3:] == \"ppm\":\n",
    "        img = Image.open(ppm_img_path)\n",
    "        png_path = os.path.join(png_dataset_dir, ppm_img_name[:-3]+'png')\n",
    "        #print(png_path)\n",
    "        img.save(png_path)\n",
    "        #img.show()\n",
    "        return png_path\n",
    "    else:\n",
    "        print(\"Non ppm file detected: {}\".format(ppm_img_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset/Training\n",
      "folder: 00031 completed\n",
      "folder: 00009 completed\n",
      "folder: 00036 completed\n",
      "folder: 00000 completed\n",
      "folder: 00038 completed\n",
      "folder: 00007 completed\n",
      "folder: 00053 completed\n",
      "folder: 00054 completed\n",
      "folder: 00039 completed\n",
      "folder: 00006 completed\n",
      "folder: 00001 completed\n",
      "folder: 00008 completed\n",
      "folder: 00037 completed\n",
      "folder: 00030 completed\n",
      "folder: 00055 completed\n",
      "folder: 00052 completed\n",
      "folder: 00048 completed\n",
      "folder: 00041 completed\n",
      "folder: 00046 completed\n",
      "folder: 00012 completed\n",
      "folder: 00015 completed\n",
      "folder: 00023 completed\n",
      "folder: 00024 completed\n",
      "folder: 00047 completed\n",
      "folder: 00040 completed\n",
      "folder: 00049 completed\n",
      "folder: 00025 completed\n",
      "folder: 00022 completed\n",
      "folder: 00014 completed\n",
      "folder: 00013 completed\n",
      "folder: 00057 completed\n",
      "folder: 00050 completed\n",
      "folder: 00059 completed\n",
      "folder: 00061 completed\n",
      "folder: 00035 completed\n",
      "folder: 00032 completed\n",
      "folder: 00004 completed\n",
      "folder: 00003 completed\n",
      "folder: 00060 completed\n",
      "folder: 00058 completed\n",
      "folder: 00051 completed\n",
      "folder: 00056 completed\n",
      "folder: 00002 completed\n",
      "folder: 00005 completed\n",
      "folder: 00033 completed\n",
      "folder: 00034 completed\n",
      "folder: 00016 completed\n",
      "folder: 00029 completed\n",
      "folder: 00011 completed\n",
      "folder: 00027 completed\n",
      "folder: 00018 completed\n",
      "folder: 00020 completed\n",
      "folder: 00045 completed\n",
      "folder: 00042 completed\n",
      "folder: 00021 completed\n",
      "folder: 00026 completed\n",
      "folder: 00019 completed\n",
      "folder: 00010 completed\n",
      "folder: 00017 completed\n",
      "folder: 00028 completed\n",
      "folder: 00043 completed\n",
      "folder: 00044 completed\n",
      "Loading /Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset/Testing\n",
      "folder: 00031 completed\n",
      "folder: 00009 completed\n",
      "folder: 00036 completed\n",
      "folder: 00000 completed\n",
      "folder: 00038 completed\n",
      "folder: 00007 completed\n",
      "folder: 00053 completed\n",
      "folder: 00054 completed\n",
      "folder: 00039 completed\n",
      "folder: 00006 completed\n",
      "folder: 00001 completed\n",
      "folder: 00008 completed\n",
      "folder: 00037 completed\n",
      "folder: 00030 completed\n",
      "folder: 00055 completed\n",
      "folder: 00052 completed\n",
      "folder: 00048 completed\n",
      "folder: 00041 completed\n",
      "folder: 00046 completed\n",
      "folder: 00012 completed\n",
      "folder: 00015 completed\n",
      "folder: 00023 completed\n",
      "folder: 00024 completed\n",
      "folder: 00047 completed\n",
      "folder: 00040 completed\n",
      "folder: 00049 completed\n",
      "folder: 00025 completed\n",
      "folder: 00022 completed\n",
      "folder: 00014 completed\n",
      "folder: 00013 completed\n",
      "folder: 00057 completed\n",
      "folder: 00050 completed\n",
      "folder: 00059 completed\n",
      "folder: 00061 completed\n",
      "folder: 00035 completed\n",
      "folder: 00032 completed\n",
      "folder: 00004 completed\n",
      "folder: 00003 completed\n",
      "folder: 00060 completed\n",
      "folder: 00058 completed\n",
      "folder: 00051 completed\n",
      "folder: 00056 completed\n",
      "folder: 00002 completed\n",
      "folder: 00005 completed\n",
      "folder: 00033 completed\n",
      "folder: 00034 completed\n",
      "folder: 00016 completed\n",
      "folder: 00029 completed\n",
      "folder: 00011 completed\n",
      "folder: 00027 completed\n",
      "folder: 00018 completed\n",
      "folder: 00020 completed\n",
      "folder: 00045 completed\n",
      "folder: 00042 completed\n",
      "folder: 00021 completed\n",
      "folder: 00026 completed\n",
      "folder: 00019 completed\n",
      "folder: 00010 completed\n",
      "folder: 00017 completed\n",
      "folder: 00028 completed\n",
      "folder: 00043 completed\n",
      "folder: 00044 completed\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "''' Load dataset into variable '''\n",
    "    \n",
    "\n",
    "# function to load training, test, and validation datasets into variables \n",
    "def load_dataset(path, png_dataset_dir):\n",
    "    all_files = []\n",
    "    print(\"Loading {}\".format(path))\n",
    "    for eachfolder in os.listdir(path):\n",
    "        abs_loc = os.path.join(path, eachfolder)\n",
    "        png_class_dir = os.path.join(png_dataset_dir, eachfolder)\n",
    "        if not os.path.isdir(abs_loc):\n",
    "            continue\n",
    "\n",
    "        #open csv for this folder\n",
    "        with open(abs_loc + \"/GT-\" + eachfolder + \".csv\", \"r\") as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "            next(csv_reader, None) # skip header\n",
    "            \n",
    "            #create traffic sign object\n",
    "            for row in csv_reader:\n",
    "                abs_file_loc = os.path.join(abs_loc, row[0])\n",
    "                png_file_loc = convert_ppm_to_png(png_class_dir, abs_file_loc, row[0]) #dir of png files, path of ppm file, name of ppm file\n",
    "                all_files.append(Traffic_Sign(png_file_loc, row[0], row[1], row[2], row[3], row[4], row[5], row[6], TSName_62[int(row[7])], row[7]))\n",
    "                \n",
    "            csv_file.close()\n",
    "        \n",
    "        print(\"folder: {} completed\".format(eachfolder))\n",
    "    return all_files\n",
    "\n",
    "\n",
    "\n",
    "# load train and test datasets into list of objects of Traffic signs\n",
    "#all_training_objs = load_dataset(\"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset/Training\") # a list of training traffic_sign_collection\n",
    "#all_testing_and_validation_objs = load_dataset(\"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset/Testing\")  # a list of testing traffic_sign_collection\n",
    "\n",
    "all_training_objs = load_dataset(training_dataset_directory, png_training_dataset_dir) # a list of training traffic_sign_collection\n",
    "all_testing_and_validation_objs = load_dataset(testing_dataset_directory, png_testing_dataset_dir)  # a list of testing traffic_sign_collection\n",
    "\n",
    "# shuffle training objects and testing objects \n",
    "shuffle(all_training_objs)\n",
    "shuffle(all_testing_and_validation_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 00035_00000.ppm has name E9a, with classID: 45\n",
      "Total number of training obj: 4591\n",
      "Total number of testing obj: 2534\n"
     ]
    }
   ],
   "source": [
    "# random test of object\n",
    "ts_pretty_print(all_training_objs[random.randint(0, len(all_training_objs))])\n",
    "print(\"Total number of training obj: {}\".format(str(len(all_training_objs))))\n",
    "print(\"Total number of testing obj: {}\".format(str(len(all_testing_and_validation_objs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TS_tf_example(TS_obj): \n",
    "    height = int(TS_obj.height)\n",
    "    width = int(TS_obj.width)\n",
    "    filename = TS_obj.fileName\n",
    "    \n",
    "    with tf.gfile.GFile(TS_obj.filePath, 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "\n",
    "    image_format = b'png'\n",
    "\n",
    "    xmins = [float(TS_obj.x1) / float(width)]\n",
    "    xmaxs = [float(TS_obj.x2) / float(width)]\n",
    "    ymins = [float(TS_obj.y1) / float(height)]\n",
    "    ymaxs = [float(TS_obj.y2) / float(height)]\n",
    "    \n",
    "    classes_text = [TS_obj.classTxt.encode('utf8')]\n",
    "    classes = [int(TS_obj.classID)]\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish converting training objects to tfRecords\n"
     ]
    }
   ],
   "source": [
    "# define tfRecord writter \n",
    "tfRecordsPath = os.path.join(tfRecordsDir, \"training.tfrecords\")\n",
    "writer = tf.python_io.TFRecordWriter(tfRecordsPath)\n",
    "\n",
    "for TS_obj in all_training_objs:\n",
    "    tf_example = create_TS_tf_example(TS_obj)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "print(\"Finish converting training objects to tfRecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modify config files of the chosen pre-trained model '''\n",
    "''' Chosen model: faster_rcnn_inception_v2_coco '''\n",
    "# run command in terminal to train\n",
    "# python3 train.py --logtostderr --train_dir=./models/train --pipeline_config_path=faster_rcnn_inception_v2_coco.config\n",
    "\n",
    "# python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path ./faster_rcnn_inception_v2_coco.config --trained_checkpoint_prefix ./models/train/model.ckpt-20000 --output_directory ./fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 31.0: Accuracy: 0.8953488372093024. 77 correct predictions in 86 pictures\n",
      "Class 0.0: Accuracy: 0.0. 0 correct predictions in 6 pictures\n",
      "Class 38.0: Accuracy: 0.9436619718309859. 201 correct predictions in 213 pictures\n",
      "Class 7.0: Accuracy: 0.03333333333333333. 3 correct predictions in 90 pictures\n",
      "Class 53.0: Accuracy: 0.9583333333333334. 23 correct predictions in 24 pictures\n",
      "Class 54.0: Accuracy: 1.0. 48 correct predictions in 48 pictures\n"
     ]
    }
   ],
   "source": [
    "class TS_detector:\n",
    "    def __init__(self):\n",
    "        frozen_model_path = '/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/obj_detection/fine_tuned_model/frozen_inference_graph.pb'\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "\n",
    "            with tf.gfile.GFile(frozen_model_path, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "            self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            self.d_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            self.d_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            self.d_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            self.num_d = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        self.sess = tf.Session(graph=self.detection_graph)\n",
    "    \n",
    "    def get_classification(self, img):\n",
    "        # Bounding Box Detection.\n",
    "        with self.detection_graph.as_default():\n",
    "            # Expand dimension since the model expects image to have shape [1, None, None, 3].\n",
    "            img_expanded = np.expand_dims(img, axis=0)    \n",
    "            (boxes, scores, classes, num) = self.sess.run(\n",
    "                [self.d_boxes, self.d_scores, self.d_classes, self.num_d],\n",
    "                feed_dict={self.image_tensor: img_expanded})\n",
    "        return boxes, scores, classes, num\n",
    "\n",
    "my_detector = TS_detector()\n",
    "\n",
    "def obj_detection_predict (img_dir, correctID):\n",
    "    # my_img_path = \"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset/png_testing/00019/00407_00001.png\"\n",
    "    all_files = []\n",
    "    correct_num = 0\n",
    "    for file in os.listdir(img_dir):\n",
    "        if file[-3:] == \"png\":\n",
    "            all_files.append(os.path.join(img_dir, file))\n",
    "\n",
    "    filename_queue = tf.train.string_input_producer(all_files) #  list of files to read\n",
    "\n",
    "    reader = tf.WholeFileReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    my_img = tf.image.decode_png(value) # use png or jpg decoder based on your files.\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "\n",
    "        # Start populating the filename queue.\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        for i in range(len(all_files)): #length of your filename list\n",
    "            image = my_img.eval() #here is your image Tensor :) \n",
    "            boxes, scores, classes, num = my_detector.get_classification(image)\n",
    "            #print(image.shape)\n",
    "            #Image.fromarray(np.asarray(image)).show()\n",
    "            boxes, scores, classes, num = my_detector.get_classification(image)\n",
    "            '''\n",
    "            print(\"boxes\")\n",
    "            print(boxes[0][0])\n",
    "            print(\"scores\")\n",
    "            print(scores[0][0])\n",
    "            print(\"classes\")\n",
    "            print(classes[0][0])\n",
    "            print(\"num\")\n",
    "            print(num)\n",
    "            '''\n",
    "            if classes[0][0] == correctID:\n",
    "                correct_num += 1\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        print(\"Class {}: Accuracy: {}. {} correct predictions in {} pictures\".format(correctID, float(correct_num)/len(all_files), correct_num, len(all_files)))\n",
    "        return correct_num\n",
    "        \n",
    "test_dir = \"/Users/kevinsu/Desktop/Udacity/machine-learning-master/projects/capstone/TSR/Dataset/png_testing\"\n",
    "list_of_classID = []\n",
    "list_of_correct_predictions = []\n",
    "for dir in os.listdir(test_dir):\n",
    "    if len(dir) == 5:\n",
    "        list_of_classID.append(dir[-2:])\n",
    "        cor_pred = obj_detection_predict(os.path.join(test_dir, dir), float(dir[-2:]))\n",
    "        list_of_correct_predictions.append(cor_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', '00', '38', '07', '53', '54', '39', '06', '01', '08', '37', '30', '55', 're']\n",
      "00031\n",
      "00000\n",
      "00038\n",
      "00007\n",
      "00053\n",
      "00054\n",
      "00039\n",
      "00006\n",
      "00001\n",
      "00008\n",
      "00037\n",
      "00030\n",
      "00055\n",
      ".DS_Store\n",
      "00041\n",
      "00046\n",
      "00012\n",
      "00023\n",
      "00024\n",
      "00047\n",
      "00040\n",
      "00049\n",
      "00025\n",
      "00022\n",
      "00014\n",
      "00013\n",
      "00057\n",
      "00059\n",
      "00061\n",
      "00035\n",
      "00032\n",
      "00004\n",
      "00003\n",
      "00060\n",
      "00058\n",
      "00051\n",
      "00056\n",
      "00002\n",
      "00005\n",
      "00034\n",
      "00016\n",
      "00029\n",
      "00027\n",
      "00018\n",
      "00020\n",
      "00045\n",
      "00042\n",
      "00021\n",
      "00019\n",
      "00010\n",
      "00017\n",
      "00028\n",
      "00043\n",
      "00044\n",
      "Accuracy score: 20.047355958958168\n"
     ]
    }
   ],
   "source": [
    "print(list_of_classID)\n",
    "for dir in os.listdir(test_dir):\n",
    "        print(dir)\n",
    "print(\"Accuracy score: {}\".format(100*np.sum(list_of_correct_predictions)/len(all_testing_and_validation_objs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
